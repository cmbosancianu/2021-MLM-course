---
title: "Day 1 code"
author:
  name: "Constantin Manuel Bosancianu"
  orcid: 0000-0001-7950-9798
  email: bosancianu@icloud.com
date: "January 20, 2021"
execute:
  eval: true
  echo: true
  warning: false
  error: false
format:
  html:
    toc: true
    code-fold: true
    toc-location: left
    theme: minty
    number-sections: true
    reference-location: margin
    embed-resources: true
---

# Introduction

I have to assume sufficient baseline knowledge of R, so we will start directly with some more advanced procedures. If you feel we're going to fast, please come see me after the first session ends, and I can suggest a few materials you can consult before the next few labs.

Irrespective of which text editor you are using, when compiling this code file the working directory will automatically be set to the folder where this code file is located in. If you want to run the code line by line, you set the working directory on your own. You can check the current working directory with the `getwd()` function, and you can set a new working directory with the `setwd()` function.

All scripts assume that you are in the directory where the code file is placed: "./01-code". They further assume that in the main "Multilevel" project folder you have the following subfolders:
- "02-data"
- "03-graphs"

If you have this folder structure in place, the code file should work from beginning to end without an error.^[As you've discovered so far, **R** is case-sensitive: it will produce an error if you're trying to read data from the `./02-Data` folder instead of the `02-data` one.]

Helpful tips:
- when you don't remember the arguments for a function, make use of the `help()` function
- when you don't remember how to extract elements from an object (vector, matrix, list, statistical output), turn to the `str()` function
- if you're missing a package on your machine, quickly install it with the following snippet of code: `install.packages("package_name", dep = TRUE, repos = "https://cran.rstudio.com")`

Though the code has been written entirely from scratch, and I have replaced most of the empirical examples, a lot of the logic of the sequences is inspired by the precursor to this course, taught by Zoltan Fazekas. I was a TA for that course for a number of years, and have learned a great deal in the process.

**Warning**: the code chunk below will install packages on your system (if these are not already installed).

```{r load-packages}
library(pacman)
p_load(tidyverse, broom, ggeffects, texreg, arm, knitr,
       broom.mixed, kableExtra, magrittr, ggthemes)
```

The `p_load()` function from the `pacman` package looks for the collection of packages you specify on your machine. If it finds them, it loads them in the working environment; if it doesn't, it downloads them, installs them, and then loads them.

# Reading data

The code chunk below assumes that the data set is in the `02-data` folder. This means we have to go one folder up from the code folder, and then into the data folder.

```{r read-data}
df_issp <- readRDS("../02-data/01-ISSP.rds")
```

We will be using a lot of functions from the `dplyr` package and from some of the other packages that make up the `tidyverse`. Despite some opinions to the contrary ([https://github.com/matloff/TidyverseSkeptic](https://github.com/matloff/TidyverseSkeptic)), I believe it is a very elegant way of thinking about coding, and one which I think will grow in importance. It pays off to learn it early and well.

The pipe operator (`%>%`) serves to take the output from a line of code, and feed it as input into the next line of code. It can be loosely translated as "with this... do that...".

```{r examine-data}
df_issp %>%
    glimpse()
```

# Codebook

Many variables added there; please check the codebook for this data set (**Codebook-ISSP.pdf**, located in the `./05-docs` folder).

The most important ones for our purposes here are:
1. `cnt`: a 2-letter code for the country from which the respondent comes from
2. `poleff`: an index of political efficacy, obtained as a mean of `V41`, `V42`, `V43` and `V44`. Higher values denote a higher level of political efficacy
3. `female`: a dummy indicator for gender (1 = woman; 0 = man)
4. `age10`: continuous indicator for age, measured in decades (32 years = 3.2 decades)
5. `educ`: number of years of full time education completed
6. `incquart`: a country-specific placement on a 4-point income ranking (1=lowest 25% income........ 4 = highest 25% income)
7. `year`: year of the survey
8. `country`: full name of the country

We will keep only the variables we're interested in.^[The function `select()` is found in multiple packages, so putting `dplyr::` in the beginning just ensures that `R` knows to use the `select()` function found in that specific package.]

```{r subset-variables}
df_issp <- df_issp %>%
    dplyr::select(cnt, year, country, poleff, female,
                  age10, educ, urban, incquart, ti_cpi) %>%
    na.omit() %>%
    mutate(female = as.factor(female),
           urban = as.factor(urban),
           incquart = as.factor(incquart))
```

# Complete vs. No pooling

## Complete pooling

**Complete pooling** designates a specification that uses the entire sample to estimate the relationship between predictors and outcome, without any thought given to group membership.

```{r complete-pooling-approach}
model1.complete <- lm(poleff ~ 1 + age10 + female + educ + urban +
                        incquart,
                      data = df_issp)

summary(model1.complete)
```

A much nicer-formatted display is available in the family of functions available in the `texreg` package.

```{r report-output-1, results='asis'}
htmlreg(list(model1.complete),
        digits = 3,
        single.row = FALSE,
        inline.css = TRUE,
        html.tag = FALSE,
        head.tag = FALSE,
        body.tag = FALSE)
```

Based on this model, all we can say is that the effect of education, or gender, on political efficacy is the same for every respondent, irrespective of which country they come from. Its virtue is that it uses information from the entire sample to estimate the relationship, which results in very small standard errors.

## No pooling

The alternative is the **no pooling** approach: running each model separately for each group. This will easily uncover how an effect varies between different countries in our sample. We can use two functions to quickly produce this: `nest()` from the `tidyr` package, and `map()` from the `purrr` package.

```{r no-pooling-approach-1}
df_nopool <- df_issp %>%
  dplyr::select(poleff, age10, female, educ, urban, incquart, cnt) %>%
  nest(data = -cnt) %>%
  mutate(mod1 = map(data,
                    ~lm(poleff ~ 1 + age10 + female + educ +
                          urban + incquart,
                        data = .)),
         results = map(mod1, tidy)) %>%
  unnest(results) %>%
  dplyr::select(-data, -mod1)
```

```{r report-output-2, results='asis'}
df_nopool %>%
    slice(1:10) %>%
    kable(digits = 3,
          caption = "Estimates from no pooling model",
          caption.above = TRUE,
          col.names = c("Country", "Variable", "Est.", "SE",
                        "t value", "p")) %>%
    kable_styling(full_width = TRUE)
```

Looking at the raw numbers doesn't help us very much, even if we were to filter by the effect we're interested in. A graphical display would be more powerful in this case.

```{r plot-no-pooling-approach}
#| fig-height: 6
#| fig-width: 8
#| dpi: 144

df_nopool %>%
  filter(term == "educ") %>%
  ggplot(aes(x = reorder(cnt, -estimate), # Reorder from low to high
             y = estimate)) +
  geom_point(size = 3) +
  geom_errorbar(aes(ymin = estimate - 1.96 * std.error, # Construct CIs
                    ymax = estimate + 1.96 * std.error),
                width = 0, linewidth = 1.25) +
  labs(x = "Country",
       y = "Effect of education on efficacy",
       title = "No pooling approach: country-by-country regressions") +
  theme_clean() +
  geom_hline(yintercept = 0, # Create dashed line denoting no effect
             linetype = "dashed",
             color = "red") +
  theme(axis.title = element_text(size = 18),
        axis.text.x = element_text(size = 14, angle = 45),
        axis.text.y = element_text(size = 14))
```

The challenge with this approach is that the only information used in the estimation originates with the group itself. Take as an example the case of Poland. Suppose that instead of 1,892 cases, it had 425 observations (about 20% of the original sample).

```{r prepare-data-poland}
set.seed(395722)
df_pl <- df_issp %>%
    filter(cnt == "PL") %>%
    slice_sample(n = 425)

df_issp_temp <- rbind(filter(df_issp, !(cnt == "PL")),
                      df_pl)
rm(df_pl)
```

```{r no-pooling-approach-2}
#| fig-height: 6
#| fig-width: 8
#| dpi: 144

df_issp_temp %>%
    dplyr::select(poleff, age10, female, educ, urban, incquart, cnt) %>%
    nest(data = -cnt) %>%
    mutate(mod1 = map(data,
                      ~lm(poleff ~ 1 + age10 + female + educ +
                              urban + incquart,
                          data = .)),
           results = map(mod1, tidy)) %>%
    unnest(results) %>%
    filter(term == "educ") %>%
    ggplot(aes(x = reorder(cnt, -estimate),
               y = estimate)) +
    geom_point(size = 3) +
    geom_errorbar(aes(ymin = estimate - 1.96 * std.error,
                      ymax = estimate + 1.96 * std.error),
                  width = 0, linewidth = 1.25) +
    labs(x = "Country",
         y = "Effect of education on efficacy",
         title = "Country-by-country regressions with small sample size for Poland") +
    geom_hline(yintercept = 0,
               color = "red",
               linetype = "dashed") +
    theme_clean() +
    theme(axis.title = element_text(size = 18),
          axis.text.x = element_text(size = 14, angle = 45),
          axis.text.y = element_text(size = 14))
```

# Multilevel model: random intercepts

We will use the `lmer()` function from the `lme4` package for these models. I have loaded the `arm` package because this automatically calls the `lme4` package, but also makes available some additional post-estimation function designed by Gelman and Hill.

## First model

```{r multilevel-ri-1}
mlm.1 <- lmer(formula = poleff ~ age10 + female + educ + urban +
                    incquart + (1 | cnt),
              data = df_issp_temp,
              REML = TRUE,
              control = lmerControl(optimizer = "bobyqa"))
```

A few comments on the syntax above:

- As long as you start with the formula syntax, there's no need to write `formula = ` every time
- The model syntax is very similar to regression. on LHS of the `~` is the outcome, while on RHS of the `~` come the predictors (and intercept for the model). These would be the "fixed-effects" in the model. After these, inside the brackets, come the random effects
- Add as many random effects as your specification requires before the `|`. In this case, I only have a random intercept, which is why I wrote only "1" before the `|`. On the RHS of the `|` comes the grouping factor(s), which in my case is `cnt`
- The formula includes a `1 + `, which denotes the fixed effect for the intercept.
- `REML = ` specifies the type of estimation that is carried out. We will cover this in one of the next sessions. Even if you don't specify it, the model will run, as REML estimation is the default
- `control = ` allows you to finely control the estimation process, including modifying the default tolerance value, or increase the number of maximum iterations that the model is allowed to run for. The default for `lmer()` is the `nloptwrap` optimizer, which for my data issues a convergence warning. Though the warning does not affect the estimates, it is still annoying to see. This is why I used an alternative optimizer - the results between the two are identical up to the 5th decimal point

```{r multilevel-ri-2}
summary(mlm.1)
```

Take a while to look a bit at the result output - looks fairly similar to that from the `lm()` function in how it is structured, except that it has a few additional fields: "Random effects" and "Correlation of Fixed Effects".^[Why no stars for the output? Because that's how the original creator of the package wanted it, for very good reasons: [https://stat.ethz.ch/pipermail/r-help/2006-May/094765.html](https://stat.ethz.ch/pipermail/r-help/2006-May/094765.html).]

## Quantities of interest

You can use a few functions to obtain the fixed effects and random effects from the model.

```{r multilevel-ri-3}
fixef(mlm.1) # The fixed effects
```

```{r multilevel-ri-4}
se.fixef(mlm.1) # SEs for the fixed effects
```

In our case, only a random intercept was specified.

```{r multilevel-ri-5}
ranef(mlm.1) # The random effects (deviations) in the model
```

```{r multilevel-ri-6}
# The SEs for random effects (function from the "arm" package).
se.ranef(mlm.1)
```

Alternatively, you can use a function in the `broom.mixed` package that extracts the same quantities (for the first 20 countries in the sample).

```{r tidied-output-1}
tidy(mlm.1) %>%
    kable(caption = "Tidied output for multilevel model",
          digits = 3,
          col.names = c("Effect", "Group", "Variable", "Est.",
                        "SE", "t value")) %>%
    kable_styling(full_width = TRUE)
```

```{r tidied-output-2}
augment(ranef(mlm.1),
        ci.level = 0.95) %>%
    slice(1:20) %>%
    kable(caption = "Augmented output for multilevel model",
          digits = 3,
          col.names = c("Group", "Variable", "Country", "Est.",
                        "QQ", "SE", "Lower CI", "Upper CI")) %>%
    kable_styling(full_width = TRUE)
```

## Comparison: no-pooling and multilevel

How do the intercepts from the no-pooling model compare to those from the multilevel one?

I use here the variant of "no-pooling" that Gelman and Hill describe: a model with country indicators. The "-1" tells **R** to estimate values for all countries, rather than use one of the countries as reference group.

```{r comparison-nopool-mlm-1}
model.np <- lm(poleff ~ as.factor(cnt) - 1 + age10 + female + educ +
                    urban + incquart,
               data = df_issp_temp)

df_nopool <- model.np %>%
    tidy() %>%
    dplyr::select(term, estimate, std.error) %>%
    filter(str_detect(term, "cnt")) %>%
    mutate(term = str_sub(term, start = -2),
           model = "nopool") %>%
    rename(cnt = term)
rm(model.np)
```

We next generate the random effects from the multilevel model.^[In the code below we have to add the value of the overall intercept, since the random effects are deviations from this overall intercept.]

```{r comparison-nopool-mlm-2}
df_mlm <- augment(ranef(mlm.1),
                  ci.level = 0.95)

df_mlm %<>%
    dplyr::select(level, estimate, std.error) %>%
    rename(cnt = level) %>%
    mutate(model = "mlm",
           estimate = estimate + fixef(mlm.1)["(Intercept)"])
```

```{r comparison-nopool-mlm-3}
#| fig-height: 7
#| fig-width: 9
#| dpi: 144

df_plot <- rbind(df_nopool, df_mlm)
rm(df_nopool, df_mlm)

df_plot %>%
    mutate(cnt = factor(cnt, levels = cnt[model == "mlm"])) %>%
    ggplot(aes(x = reorder(cnt, -estimate),
               y = estimate),
           color = model,
           group = model) +
    geom_point(size = 3,
               position = position_dodge(width = 0.75),
               aes(color = model)) +
    labs(x = "Country",
         y = "Baseline level of political efficacy") +
    theme_clean() +
    geom_errorbar(aes(ymin = estimate - 1.96 * std.error,
                      ymax = estimate + 1.96 * std.error,
                      color = model),
                  linewidth = 1.25,
                  position = position_dodge(width = 0.75),
                  width = 0) +
    scale_color_colorblind(name = "Specifications",
                           breaks = c("nopool","mlm"),
                           labels = c("No pooling", "MLM")) +
    theme(axis.title = element_text(size = 18),
          axis.text.x = element_text(size = 14, angle = 45),
          axis.text.y = element_text(size = 14),
          legend.position = "bottom")

rm(df_plot, mlm.1)
```

## ICC

We determine the need for a MLM by running a null model, and then computing the ICC.

```{r run-null-model}
mlm.0 <- lmer(poleff ~ 1 + (1|cnt),
              data = df_issp_temp,
              control = lmerControl(optimizer = "bobyqa"))

summary(mlm.0)
```

The output already gives you all the needed information to compute the ICC.

```{r computing-icc}
0.0908 / (0.0908 + 0.5221)

rm(df_issp_temp, mlm.0)
```

# Add level-2 predictors

I will first re-estimate the initial model on the full data set, with the proper data for Poland (as opposed to the truncated sample).

```{r add-l2-predictors-1}
mlm.1 <- lmer(formula = poleff ~ 1 + age10 + female + educ +
                  urban + incquart + (1 | cnt),
              data = df_issp,
              REML = TRUE,
              control = lmerControl(optimizer = "bobyqa"))

mlm.2 <- lmer(formula = poleff ~ 1 + age10 + female + educ +
                  urban + incquart + ti_cpi +
                  (1 | cnt),
              data = df_issp,
              REML = TRUE,
              control = lmerControl(optimizer = "bobyqa"))
summary(mlm.2)
```

```{r compare-2-models, results='asis'}
htmlreg(list(mlm.1, mlm.2),
        digits = 3,
        custom.model.names = c("No L2 predictor",
                               "L2 predictor"),
        caption = "Comparison of 2 multilevel specifications",
        caption.above = TRUE,
        custom.coef.map = list("(Intercept)" = "Intercept",
                               "age10" = "Age (in decades)",
                               "female1" = "Gender (woman)",
                               "educ" = "Education",
                               "urban1" = "Urban settlement",
                               "incquart2" = "2nd income quartile",
                               "incquart3" = "3rd income quartile",
                               "incquart4" = "4th income quartile",
                               "ti_cpi" = "Corruption perceptions index"),
        single.row = FALSE,
        inline.css = TRUE,
        html.tag = FALSE,
        head.tag = FALSE,
        body.tag = FALSE)
```

# Optional home tasks
I have added in the `./02-data` subfolder a data set on which you can practice some of your newly-acquired MLM skills. The data comes from round 6 of the European Social Survey, and has been cleaned to the point where it's ready to be used.

The data also comes with an associated codebook, which you can find deposited in the `./05-docs` subfolder.

Try a set of multilevel models predicting satisfaction with democracy.

1. A null model
2. A random intercept model which includes only level-1 predictors for satisfaction.
3. A random intercept model with all L1 predictors from above, and 2-3 level-2 predictors as well.

Please save the syntax file in which you're running these specifications, as next days' tasks will build on them.


# Package versions

Package versions used in this script.^[Useful when trying to replicate the analyses above.]

```{r package-versions}
sessionInfo()
```